---
title: "Statistics with R - session 3 - Multivariate analysis"
author: Géraldine Derroire
institute: Cirad - UnB
date: last-modified
format: 
  revealjs:
    theme: solarized
    output-location: fragment 
    slide-number: true
    preview-links: true
    chalkboard: true
    link-external-icon: true
    link-external-newwindow: true
    incremental: true
execute:
  echo: true   
  warning: true
  message: true 
  cache: true
editor: 
  markdown: 
    wrap: sentence
---

## Why multivariate analyses ?

**Multivariate analysis** are used to study the joint distribution of several variables, *i.e.* the variation of each variable and their correlations.

* **Clustering methods** aim to group observations based on similarities across multiple variables.

* **Ordination methods** aim to rearrange the observations in a lower-dimensional space to reduce the dimensionality of the data while preserving the main patterns of variation.

## Why multivariate analyses ?

**Ordination methods** can be used for: 

  * the identification axes of co-variation between several variables (*eg*: co-variation between climatic variables or soil variables along environmental gradients, co-variation of functional traits along specta of functional strategies...)
  
  * the study ecological communities by jointly considering the occurrence or abundance of multiple species

## Structure of multivariate data {.smaller}


[*n*]{style="color:indianred;"} observations (in row) of [*p*]{style="color:indianred;"} variables (in column), where [$x_{ij}$]{style="color:indianred;"} is the value of the variable [*j*]{style="color:indianred;"} for observation [*i*]{style="color:indianred;"}:


\begin{bmatrix}
x_{11} & x_{12} & \cdots & x_{1p} \\
x_{21} & x_{22} & \cdots & x_{2p} \\
\vdots & \vdots & \ddots & \vdots \\
x_{n1} & x_{n2} & \cdots & x_{np}
\end{bmatrix}

[*Example:*]{.fragment}

* values of *p* environmental variables in *n* sites (observations)

* floristic composition (*p* species = variables) in *n* sites

* values of *p* functional traits (variables) for *n* species (observations)


## Package *vegan*

There are many packages to do multivariate analyses: [stats]{style="color:indianred;"} (base package), [ade4]{style="color:indianred;"}, [FactoMine]{style="color:indianred;"}, [vegan]{style="color:indianred;"}.

We will mostly work with [vegan]{style="color:indianred;"}, let's load it:

```{r}
library(vegan)
```


## Let's work with data on understory vegetation in Fennoscandia {.smaller}

[These data are available in the package [vegan]{style="color:indianred;"} and include:]{style="font-size: 30px"}

::::: columns
::: {.column width="50%"}

* [A floristic table of cover of understory vegetation (species in colum and sites in row):]{style="font-size: 30px"}

::: fragment
```{r}
data(varespec)
varespec[1:5, 1:5] # display only a subset
```
:::

:::

::: {.column width="50%"}

* [Soil data on the 24 plots]{style="font-size: 30px"} 

::: fragment
```{r}
data(varechem)
varechem[1:5, 1:5] # display only a subset
```
:::

:::
:::::

[[For more information on these data see [Väre,Ohtonen and Oksanen (1995)](https://www.researchgate.net/publication/227830523_Effects_of_reindeer_grazing_on_vegetation_in_dry_Pinus_sylvestris_forests){preview-link="false"}]{style="font-size: 22px"}]{.fragment}



# Unconstrained ordination methods

<!-- ressource

https://gavinsimpson.github.io/physalia-multivariate/03-wednesday/slides.html#1

https://r.qcbs.ca/workshop09/book-en/setting-up-our-goals.html

Marchand + Eric --> 

## Principle

[Unconstrained ordination methods are used to **visualise and explore the relationships among variables or observations** without imposing any specific constraints on the relationships.]{style="font-size: 30px"}

[The objective is to identify a few axes that capture most of the variation in a multidimensional dataset, allowing for a simplified yet informative representation.]{style="font-size: 30px"}

[This allows to **visualise similarities among observations**, as more similar observations will be closer in the reduced-dimensional spaces.]{style="font-size: 30px"}

<!-- voir aussi Marchand session 2 sur l'explication des différentes distances--> 

## PCA - Principle

[In a cloud of observations in a p-dimension space (*p* variables), a **Principal Components Analysis** fits:]{style="font-size: 30px"}

::::: columns
::: {.column width="60%"}

* [a [first line]{style="color:red;"} minimising the **Euclidean distance** between the line and the observations, hence maximising the variance captured.]{style="font-size: 30px"}

* [a [second line]{style="color:lightgreen;"}, orthogonal to the first one, capturing the maximum remaining variance.]{style="font-size: 30px"}

* [a third, a fourth, .... until we have $p$ lines]{style="font-size: 30px"}

:::

::: {.column width="40%"}
![](PCA3.png)
[Source: [E. Marcon](https://ericmarcon.github.io/Cours-R-Geeft/Ordination.html){preview-link="false"}]{style="font-size: 22px"}

:::
:::::

[[Each of these lines is a **Principal Component** (PC) and is associated with an **eigenvalue** indicating how much variance it explains.]{style="font-size: 30px"}]{.fragment}

## PCA - Principle

[Alternative representation:]{style="font-size: 30px"}

![](PCA4.png)
[Source: [G. Simpson](https://gavinsimpson.github.io/physalia-multivariate/02-tuesday){preview-link="false"}]{style="font-size: 22px"}



## PCA - Running a PCA

Let's fit a PCA on the soil data, using the function [pca]{style="color:indianred;"}:

```{r}
soil_pca <- pca(varechem, scale = TRUE)
```

[⚠️ As the PCA is based on Euclidean distances, the variables needs to be express in comparable units. For this, we need to standardise them to a mean of 0 and a standard deviation of 1, using the argument *scale = TRUE*]{.fragment}


## PCA - Output {.smaller}

::::: columns
::: {.column width="70%"}

```{r}
summary(soil_pca)
```

:::

::: {.column width="30%"}
* The inertia is the total variance (all of it is unconstrained).

* The eigenvalues are the variance explained by each PC.

* We also get the proportion of variance explained by each PC, an the cumulative proportion.

:::
:::::

## PCA - Importance of components

[As the objective is to reduce the dimensionality of our data, we will only interpret a small number of PCs.]{style="font-size: 30px"}

::::: columns
::: {.column width="50%"}
```{r}
screeplot(soil_pca, bstick = TRUE)
```
:::

::: {.column width="50%"}
[[The [screeplot]{style="color:indianred;"} shows the variance explained by each PC.]{style="font-size: 30px"}]{.fragment}

[[The broken stick distribution shows the expected distribution of the variance if it was randomly distributed among PCs.]{style="font-size: 30px"}]{.fragment}
:::
:::::

[[Here we can focus on the two first PCs]{style="font-size: 30px"}]{.fragment}


## PCA - Visualisation

A [biplot]{style="color:indianred;"} shows the observations and variables in a same 2d-space defined by the chosen PCs:

::::: columns
::: {.column width="60%"}
```{r}
#| fig-width: 5
#| fig-height: 4
biplot(soil_pca, scaling = "symmetric")
```
:::

::: {.column width="40%"}
[[The red arrows represent the variables, and the black numbers the observations (here the *sites*).]{style="font-size: 30px"}]{.fragment}

[[The longer the arrows, the better the variable is represented by the displayed PCs.]{style="font-size: 30px"}]{.fragment}
:::
:::::

## PCA - Visualisation 

::::: columns
::: {.column width="50%"}

[To focus on the observations, we chose *type 1 scaling* that attempts to preserved the distances.]{style="font-size: 30px"}

```{r}
#| fig-width: 5
#| fig-height: 4
biplot(soil_pca, scaling = 1)
```
:::

::: {.column width="50%"}
[The distance between two observations can be interpreted as their similarity.]{style="font-size: 30px"}

[[💡 In [vegan]{style="color:indianred;"}, type 1 scaling can be obtained by *scaling = "sites"*.]{style="font-size: 25px"}]{.fragment}
:::
:::::

## PCA - Visualisation 

::::: columns
::: {.column width="50%"}

[To focus on the variables, we chose *type 2 scaling*: ]{style="font-size: 30px"}

```{r}
#| fig-width: 5
#| fig-height: 4
biplot(soil_pca, scaling = 2)
```

:::

::: {.column width="50%"}

[The angles between variables reflect their correlations.]{style="font-size: 30px"}

* [Variables at 180° are negatively correlated.]{style="font-size: 30px"}

* [Variables at 0° are positively correlated.]{style="font-size: 30px"}

* [Variables at 180° are not correlated.]{style="font-size: 30px"}

[[💡 In [vegan]{style="color:indianred;"}, type  scaling can be obtained by *scaling = "species"*.]{style="font-size: 25px"}]{.fragment}

:::
:::::

## PCA - Visualisation

[To represent different PCs, we can specify them using the argument *choice*:]{style="font-size: 30px"}

```{r}
#| fig-width: 5
#| fig-height: 4
biplot(soil_pca, scaling = "symmetric", 
       choices = c(1, 3)) # PCs 1 and 3
```

<!-- TO DO carry on from here -->

## CA - Principle

[As PCA is based on Euclidean distances, it assumes *linear relationships* between variables, and between variables and underlying gradients.]{style="font-size: 35px"} 

[When analysing **floristic composition along ecological gradients** (with species as variables), this assumption is often violated, as many species exhibit *unimodal distributions* along gradients.]{style="font-size: 35px"} 

::: fragment

[For this type of data, we can use a **Correspondence Analysis** (CA), based on $\chi^2$ distances, which are better suited for detecting unimodal responses.]{style="font-size: 35px"} 

[In addition, CA is *not* affected by double zeros: sites with a lot of shared absences are *not* interpreted as being more similar.]{style="font-size: 35px"} 

:::

## CA - Running a CA

We can run a CA on a floristic table, *i.e.* a contingency table presenting the presence/absence or the abundance of *p* species in *n* sites.

To run a CA in [vegan]{style="color:indianred;"}, we use the function [ca]{style="color:indianred;"}:

```{r}
veg_ca <- ca(varespec)
```

## CA - Output {.smaller}

::::: columns
::: {.column width="70%"}

```{r}
summary(veg_ca)
```
:::

::: {.column width="30%"}
* The output of a CA is very similar to a PCA.

* We get the eigenvalues explained by each Correspondence Axis (CA).

:::
:::::


## CA - Importance of components

[As with a PCA, we can look at the variance explained by each CA:]{style="font-size: 30px"}


```{r}
screeplot(veg_ca, bstick = TRUE)
```

::: notes
here we would consider 5 axes
:::


## CA - Visualisation {.smaller}

[In CA biplots, species are shown as points representing the optima of the species along the gradients. Abundance of species declines in concentric circles away from the optima.]{style="font-size: 30px"}

::::: columns
::: {.column width="33%"}
```{r}
#| fig-width: 5
#| fig-height: 4
plot(veg_ca, scaling = "species",
     main = "Scaling: species") # title
```
:::

::: {.column width="33%"}

```{r}
#| fig-width: 5
#| fig-height: 4
plot(veg_ca, scaling = "sites",
     main = "Scaling: sites") # title
```

:::

::: {.column width="33%"}
```{r}
#| fig-width: 5
#| fig-height: 4
plot(veg_ca, scaling = "symmetric",
     main = "Scaling: symmetric") # title
```
:::
:::::

[[💡 To visualise a CA, we use the function [plot]{style="color:indianred;"}. The use of scaling is similar to a PCA.]{style="font-size: 25px"}]{.fragment}

## CA - Visualisation {.smaller}

::::: columns
::: {.column width="50%"}

[We can focus on the species...]{style="font-size: 30px"}

```{r}
#| fig-width: 5
#| fig-height: 4
plot(veg_ca, scaling = "species",
     main = "Scaling: species", # title
     display = "species")
```

[[The proximity of species indicate that they are presents in similar sites.]{style="font-size: 28px"}]{.fragment}

:::

::: {.column width="50%"}

[... or on the sites.]{style="font-size: 30px"}

```{r}
#| fig-width: 5
#| fig-height: 4
plot(veg_ca, scaling = "sites",
     main = "Scaling: sites", # title
     display = "sites")
```

[[The proximity of sites indicate that they have similar communities.]{style="font-size: 28px"}]{.fragment}

:::
:::::

::: notes
look at examples on the plots
:::


## PCoA - Principle

[The **Principal Coordinate Analysis** (PCoA), also called **metric multidimentional scaling** (MDS), is a more general method.]{style="font-size: 30px"}

[PCoA can use many types of distance (not only Euclidean or $\chi^2$):]{style="font-size: 30px"}

* [for abundance data, we often used the distance of **Bray-Curtis**.]{style="font-size: 30px"}

* [for presence/absence data, we often use the distance of Jaccard (*i.e.* 1 - Jaccard Index).]{style="font-size: 30px"}

[[These distances range from 0 (identical species composition) to 1 (no shared species).
They focus on shared abundance and thus ignore the double absences.]{style="font-size: 30px"}]{.fragment}

[[💡 A PCoA with Euclidian distance is equivalent to a PCA, and with $\chi^2$ distance to a CA.]{style="font-size: 25px"}]{.fragment}


## PCoA - Running a PCoA {.smaller}

[Let's do a PCoA on abundance data using Bray-Curtis distance.]{style="font-size: 30px"}

[We first need to calculate the distance between sites, using [vegdist]{style="color:indianred;"}:]{style="font-size: 30px"}

```{r}
veg_dist <- vegdist(varespec, method = "bray")
veg_dist
```

::: notes
explain the distance matrix between pairs of plots
:::

## PCoA - Running a PCoA

[We use [pco]{style="color:indianred;"} to run a PCoA.]{style="font-size: 30px"}

[When using Bray-Curtis distance, we can get negative eigenvalues (corresponding to distances in an imaginary space). To avoid this, we can do a Lingoes correction.]{style="font-size: 30px"}

```{r}
veg_pcoa <- pco(veg_dist, 
                add = "lingoes") # correction
```

## PCoA - Output {.smaller}

```{r}
summary(veg_pcoa)
```

::: notes 
we can ignore the warning, if we are just visualising the summary (and not doing anything afterwards)

same kind of output (but here MDS for metric multidimensional scalling)
:::

## PCoA - Importance of components

```{r}
screeplot(veg_pcoa, bstick = TRUE)
```

::: notes
idem other methods
:::

## PCoA - Visualisation {.smaller}

::::: columns
::: {.column width="50%"}

[We plot the observations using [plot]{style="color:indianred;"} and then add the species scores:]{style="font-size: 30px"}

```{r}
# get species scores
scrs <- scores(veg_pcoa, 
               choices = 1:2) # axes

# take the weighted averages scores 
  # (weighed by abundance)
spp_scrs <- wascores(scrs,
                     varespec) # weights
```
:::

::: {.column width="50%"}

```{r}
#| fig-width: 5
#| fig-height: 5
# plot the sites
plot(veg_pcoa)

# add species to the plot
text(spp_scrs, labels = rownames(spp_scrs), 
     col = "red", cex = 0.8) # color and size
```
:::
:::::

::: notes
results are not far from the one obtained with the CA
:::

## NMDS - Principle

[**Non-metric multidimentional scaling** is an ordination method used in similar contexts as PCA, CA and PCoA, but working very differently:]{style="font-size: 30px"}

* [as in PCoA, we can choose the measure of distance (usually Bray-Curtis)]{style="font-size: 30px"}

* [the number of axes is set *a priori* (usually 2)]{style="font-size: 30px"}

* [an iterative algorithm moves the sites until the distances between sites are the closest possible to the actual multivariate distances (based on the chosen distance metric).]{style="font-size: 30px"}

[[NMDS is non-metric as it focussed on the **rank order of distances** rather than on the actual distance, making it very flexible and robust.]{style="font-size: 30px"}]{.fragment}


## NMDS - Running a NMDS

We now work with the [dune]{style="color:indianred;"} data, a floristic table of dune vegetation.

We run the NMDS using [metaMDS]{style="color:indianred;"}. The default number of axes is *2*.

```{r}
set.seed(22)
data(dune)
dune_nmds <- metaMDS(dune, 
                     distance = "bray", # Bray-Curtis is the default
                     trace = FALSE)
```

[[As there is a random component in the analyse, I've set a seed so that we all get the same results.]{style="font-size: 22px"}]{.fragment}

::: notes
we change the data because varespec doesn't work very well here...

trace = FALSE is to avoid having having the output of each iteration

no need to set the seed, or can be set to any number
:::



## NMDS - Output {.smaller}

::::: columns
::: {.column width="50%"}

```{r}
dune_nmds
```
:::

::: {.column width="50%"}
[The output gives:]{style="font-size: 30px"}

* [a reminder of the data, the distance metric, the number of dimensions]{style="font-size: 30px"}

* [the **stress**: a value < 0.1 is good, a value < 0.2 is acceptable, a value > 0.2 is poor]{style="font-size: 30px"}

* [the number of times the algorithm converged (number of best solutions). If less than 2 convergence, the result is unstable.]{style="font-size: 30px"}

:::
:::::

## NMDS - Convergence issue {.smaller}

[If the algorithm does not converge, we can: ]{style="font-size: 30px"} 

::::: columns
::: {.column width="50%"}

* [add iterations from previous best solution:]{style="font-size: 30px"}

::: fragment
```{r}
dune_nmds <- metaMDS(dune, 
                     previous.best = dune_nmds, 
                     trace = FALSE)
dune_nmds
```
:::

:::

::: {.column width="50%"}
* [or rerun the NMDS, increasing the number of iterations:]{style="font-size: 30px"}

::: fragment
```{r, eval = FALSE}
metaMDS(dune,
        try = 50, # the default is 20
        trace = FALSE)
```
:::

:::
:::::

::: notes
second solution not ran
:::

## NMDS - Visualisation

```{r}
#| fig-width: 6
#| fig-height: 5
plot(dune_nmds, 
     type ="t") # display the names of sites and species
```



## NMDS - Goodness of fit

::::: columns
::: {.column width="50%"}

[To assess the goodness of fit, we can plot a Shepard plot with [stressplot]{style="color:indianred;"}:]{style="font-size: 30px"}

```{r}
#| fig-width: 4
#| fig-height: 4
stressplot(dune_nmds,
           main = "Shepard plot")
```

:::

::: {.column width="50%"}

::: fragment

[The Shepard plot shows ordination distance *vs* observed dissimilarity.]{style="font-size: 30px"}

[It also gives the R^2^, for non-metric fit $$R^2 = 1 - Stress^2$$]{style="font-size: 30px"}

* [The smaller the *stress*, the better the fit.]{style="font-size: 30px"}

* [The higher the *R^2^*, the better the fit.]{style="font-size: 30px"}

:::

:::
:::::


::: notes

steps = groups of tied or nearly tied dissimilarity values being assigned the same rank

:::

## NMDS - Number of dimensions {.smaller}

[To see how the stress decreases when we add dimensions, we can fit a NMDS with number of dimensions ranging from 1 to 10 (or more), and plot the stress *vs* the number of dimensions:]{style="font-size: 30px"}

::::: columns
::: {.column width="60%"}


```{r}
k_vec <- 1:10 # number of dimensions
stress <- numeric(length(k_vec)) # create a vector of numeric
veg_dij <- metaMDSdist(dune, trace = FALSE) # calculate dissimilarities
set.seed(25)
for(i in seq_along(k_vec)) { # run an NMDS for 1 to 10 dimensions
    sol <- metaMDSiter(veg_dij, k = i, # run the NMDS
                       trace = FALSE)
    stress[i] <- sol$stress # extract the stress
}
```
:::

::: {.column width="40%"}

```{r}
#| fig-width: 4
#| fig-height: 4
plot(k_vec, stress, type = "b", 
     ylab = "Stress", xlab = "Dimensions")
```

:::
:::::


::: notes
we will see loops later

here we calculate the dissimilarity outside the loop as it is not random, so no need to do it several tumes

and seq_along generate a sequence of interger of the same length as k_vec

type ="b" give the lines between the dots
:::


## Summary on unconstrained ordination methods {.smaller}

```{r, echo = FALSE}
resum <- data.frame(Method = c("PCA", "CA", "PCoA", "NMDS"),
                    Principle = c("Linear method based on Euclidian distance",
                                  "Unimodal method based on chi^2^ distance",
                                  "Metric based on several types of distances",
                                  "Based on rank, with several types of distances"),
                    Use = c("Environmental data (or species data on short gradients)",
                            "Species data with non linear responses. chi^2^ give more weight to rare species than Bray-Curtis",
                            "Any kind of data. Bray-Curtis more sensitive to abundant species",
                            "Very flexible and robust for non-linear responses, many zeros..."))
knitr::kable(resum)
```

# Clustering

## Principle

**Hierachical clustering** aims to create groups of observations that are similar accross a set of variable.

Observations are progressively aggregated based on their similarity until all are merged into a single group.

The clustering results in a tree-like structure called **dendrogram**, which illustrates the proximity between observations.

## Performing the clustering

Let's do a clustering of the plots based on the soil data.

* As for the PCA, we first need to standardise the variables:

::: fragment
```{r}
soil_norm <- as.data.frame(scale(varechem))
```
:::

* We then compute the distance matrix:

::: fragment
```{r}
soil_dist <- dist(soil_norm)
```
:::

* We then perform the clustering using [hclust]{style="color:indianred;"}. Here we use the method of Ward:

::: fragment
```{r}
soil_clust <- hclust(soil_dist, method = "ward.D2")
```
:::

## Different methods of clustering

Different methods of clustering can be used.

* *Ward clustering* minimise intra-group variance

* *single linkage*: connects clusters based on the shortest distance between any two points within those clusters 

* *complete linkage*: connects clusters based on the longest distance between any two points within those clusters

* *average linkage*: connects clusters based on the average distance between all pairs of points within those clusters

[[The best methods depends on the data, but the Ward method is often a good choice.]{style="font-size: 30px"}]{.fragment}

## Dendrogram

::::: columns
::: {.column width="70%"}

[We use [plot]{style="color:indianred;"} to get the dendrogram.]{style="font-size: 30px"}

```{r}
plot(soil_clust)
```

:::

::: {.column width="30%"}
* [Horizontal lines represent grouping.]{style="font-size: 30px"}

* [The length of vertical lines correspond to the distance between groupings.]{style="font-size: 30px"}

:::
:::::

[[Here there is not obvious choice for the number of groups... We can possibly make 3 or 5 groups.]{style="font-size: 30px"}]{.fragment}

::: notes
vertical distance: here for instance, making 2 groups is not very different from making 3 groups

voir aussi around 16, 18, 14

show on the backboard an example where we would have a clear choice
:::


## Extract the groups

We can extract the groups using [cutree]{style="color:indianred;"}:

```{r}
# 3 groups
soil_3_group <- cutree(soil_clust, k = 3)

# 5 groups
soil_5_group <- cutree(soil_clust, k = 5)
soil_5_group # this is a name vector
```


## Compare groups with PCA {.smaller}

[We can also represent the groups on the PCA biplot:]{style="font-size: 30px"}

::::: columns
::: {.column width="65%"}

```{r}
# extract the scores of the sites on the two first PCs
  dt_soil_groups <- as.data.frame(scores(soil_pca, 
                           scaling = "sites", # type of scaling
                           display = "sites", # scores we want
                           choices = 1:2)) # axes
# check that plots are in the same order
  all(rownames(dt_soil_groups) == rownames(soil_3_group))
  all(rownames(dt_soil_groups) == rownames(soil_5_group))

# add groups to the PCs data 
  dt_soil_groups$G3 <- as.factor(soil_3_group)
  dt_soil_groups$G5 <- as.factor(soil_5_group)
```

:::

::: {.column width="35%"}
```{r}

head(dt_soil_groups)
```

:::
:::::


## Compare groups with PCA {.smaller}

::::: columns
::: {.column width="50%"}

```{r}
library(ggplot2)
ggplot(dt_soil_groups,
       aes(x = PC1, y = PC2, color = G3)) + 
  geom_text(aes(label = rownames(dt_soil_groups)), 
            size = 8) + 
  theme_classic()
```

:::

::: {.column width="50%"}

```{r}
#
ggplot(dt_soil_groups,
       aes(x = PC1, y = PC2, color = G5)) + 
  geom_text(aes(label = rownames(dt_soil_groups)),
            size = 8) + 
  theme_classic()
```

:::
:::::


[[💡 Note how we retrieve the scores of the ordination to be able to use ggplot to customise the plot.]{style="font-size: 30px"}]{.fragment}

::: notes
you can retreive everything from the ordinations, need to check the vignette and help of the package vegan to learn how to do it...
:::

# Constrained ordination methods

## Principle

[In constrained ordination methods, the choice of the axes is based on the response to explanatory variables.
These methods combine the concepts of **ordination** and **regression**.]{style="font-size: 30px"}

::: fragment

[The objective of constrained ordinations is to identify **relationships between a multivariate response table and a multivariate explanatory table**.]{style="font-size: 30px"}

::::: columns
::: {.column width="50%"}

[Constrained ordination can be used to identify relationships between the species composition of communities (here *Y*) and environmental variables (here *X*).]{style="font-size: 28px"}
:::

::: {.column width="50%"}
![](constrained.png)
:::
:::::

:::

## Collinearity {.smaller}

[As in multiple linear regression, we need to avoid collinearity of explanatory variables.]{style="font-size: 30px"}

[In a real study, we will choose the variables to include based on our **hypotheses**.]{style="font-size: 30px"}

::::: columns
::: {.column width="50%"}

[We can look use the PCA of soil variables to choose variables with little correlation:]{style="font-size: 30px"}

```{r}
#| fig-height: 6
biplot(soil_pca, scaling = 2, display = "species")
```

:::

::: {.column width="50%"}

[Let's choose *pH*, *N*, *Mo*, *P*, and check how correlated they are:]{style="font-size: 30px"}

```{r}
#| message: false
GGally::ggpairs(soil_norm[,c("pH", "N", "Mo", "P")])
```
:::
:::::


## RDA - Principle

**Redundancy analysis** (RDA) is the constrained equivalent of Principal Component Analysis (PCA).

It is therefore based on Euclidean distance and assumes **linear** relationships between species and environmental variables.


## RDA - Hellinger transformation 

To do a RDA (or a PCA) on a table of abundance of species, a Hellinger transformation is required. 
Hellinger distance has a more linear response to changes in species abundance.

We can do this transformation using [decostand]{style="color:indianred;"}:

```{r}
spec_hel <- decostand(varespec, method  ="hellinger")
```


## RDA - Running a RDA 

[We run the RDA with [rda]{style="color:indianred;"}:]{style="font-size: 30px"}

```{r}
vare_rda <- rda(spec_hel ~ pH + N + Mo + P, # formula
                data = soil_norm)
```

* [The formula is quite similar to the formula of a regression, but here the response variable is the abundance table (after Hellinger transformation).]{style="font-size: 30px"}

* [We use the soil explanatory variables that we already standardised.]{style="font-size: 30px"}

## RDA - Output {.smaller}

::::: columns
::: {.column width="50%"}

```{r}
summary(vare_rda)
```

:::

::: {.column width="50%"}

[The output includes:]{style="font-size: 30px"}

* [The inertia (*i.e.* total variance) partitioned into a part explained by the constrained axes, and a residual part (unconstrained).]{style="font-size: 30px"}

* [The first axes (RDA1, RDA2, ...) are the constrained axes, representing the variation explained by the explanatory variables.]{style="font-size: 30px"}

* [The remaining axes (PC1, PC2, ...) are unconstrained and represent the residual variation not explained by the explanatory variables.]{style="font-size: 30px"}
:::
:::::

::: notes
not great as not much variation explained by the constrained part...
:::


## RDA - Goodness of fit

```{r}
RsquareAdj(vare_rda)
```

* $R^2$ is the percentage of variance explained by the constrained part (as shown in the output)

* $R^2$ adjusted is corrected to take into account the number of explanatory variables 

::: notes
as seen, not super good model...
:::

## RDA - VIF

As for a linear regression, we can use the VIF (*variance inflation factor*) obtained with [vif.cca]{style="color:indianred;"}, to check that there is not too much collinearity (too much if > 10):

```{r}
vif.cca(vare_rda)
```


## RDA - Significance testing {.smaller}

[The significance of the RDA is obtained with [anova.cca]{style="color:indianred;"}.]{style="font-size: 30px"}

::::: columns
::: {.column width="50%"}

[Significance of the whole model:]{style="font-size: 30px"}

```{r}
anova.cca(vare_rda)
```

:::

::: {.column width="50%"}

::: fragment

[Significance of each explanatory variable:]{style="font-size: 30px"}

```{r}
anova.cca(vare_rda, by = "term")
```

:::
:::
:::::

## RDA - Visualisation

RDA is visuallised using a triplot (as it represents the sites, the species and the environmental variables).

::::: columns
::: {.column width="50%"}

[Scaling 1 focusses on the sites:]{style="font-size: 30px"}

```{r}
#| fig-width: 4
#| fig-height: 4
plot(vare_rda, scaling = 1)
```

:::

::: {.column width="50%"}

[Scaling 2 focusses on the species:]{style="font-size: 30px"}

```{r}
#| fig-width: 4
#| fig-height: 4
plot(vare_rda, scaling = 2)
```

:::
:::::


## CCA - Principle

**Canonical Correspondence Analysis** (CCA) is the constrained equivalent of Correspondence Analysis (CA).

It is therefore based on $\chi^2$ distance and assumes **unimodal** relationships between species and environmental variables.


## CCA - Running a CCA

[We run the CCA with [cca]{style="color:indianred;"}:]{style="font-size: 30px"}

```{r}
vare_cca <- cca(spec_hel ~ pH + N + Mo + P,
                data = soil_norm)
summary(vare_cca)
```

## CCA - Interpretation

The rest is similar to the RDA:

```{r, eval=FALSE}
RsquareAdj(vare_cca)
anova.cca(vare_cca)
anova.cca(vare_cca, by = "term")
plot(vare_cca, scaling = 1)
plot(vare_cca, scaling = 2)
```

::: notes
not ran here, diy
:::

## db-RDA - Principle

**Distance-based Redundancy analysis** (db-RDA) is the constrained equivalent of Principal Coordinate Analysis (PCoA).

It can therefore be used with a variety of distance measures (commonly Bray-Curtis)


## db-RDA - Running db-RDA

[We run the db-RDA with [dbrda]{style="color:indianred;"}:]{style="font-size: 30px"}

```{r}
vare_dbrda <- dbrda(spec_hel ~ pH + N + Mo + P,
                data = soil_norm,
                distance = "bray")
summary(vare_dbrda)
```

## db-RDA - Interpretation

The rest is similar to the RDA:

```{r}
RsquareAdj(vare_dbrda)
anova.cca(vare_dbrda)
anova.cca(vare_dbrda, by = "term")
plot(vare_dbrda, scaling = 1)
plot(vare_dbrda, scaling = 2)
```

::: notes
not ran here, diy
:::


# Acknowledgments

::: {.nonincremental}

* Marchand P. *Analyses et modélisation des données écologiques* [in French](https://pmarchand1.github.io/ECL7102/){preview-link="false"}

* Marcon E. *cours-R-Geeft* [in French](https://ericmarcon.github.io/Cours-R-Geeft/){preview-link="false"}

* Simpson G. *Multivariate data analysis with R and vegan* [here](https://github.com/gavinsimpson/physalia-multivariate?tab=readme-ov-file){preview-link="false"}

* QCBS R Workshop Series *Multivariate Analyses in R* [here](https://r.qcbs.ca/workshop09/book-en/){preview-link="false"} and *Advanced Multivariate Analyses in R* [here](https://r.qcbs.ca/workshop10/book-en/index.html){preview-link="false"}

:::


## Resources

::: {.nonincremental}

* Simpson G. *Multivariate data analysis with R and vegan* [here](https://gavinsimpson.github.io/physalia-multivariate/02-tuesday){preview-link="false"} and [here](https://gavinsimpson.github.io/physalia-multivariate/03-wednesday){preview-link="false"} (includes some advice on how to customise the plots and extract the results)

* QCBS R Workshop Series *Multivariate Analyses in R* [here](https://r.qcbs.ca/workshop09/book-en/){preview-link="false"} and *Advanced Multivariate Analyses in R* [here](https://r.qcbs.ca/workshop10/book-en/index.html){preview-link="false"}

:::


## Resources to go further

Package [ggvegan](https://rdrr.io/github/gavinsimpson/ggvegan/#vignettes){preview-link="false"}
to make ggplot style graph from ordination results (not on CRAN)

